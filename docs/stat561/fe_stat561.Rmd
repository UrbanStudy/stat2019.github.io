---
title: "STAT561"
author: 'STAT561 Fall 2018 Final Exam'
date: "12/04/2018"
output: html_document
---


#### 1. Find the general formula for $\Gamma(\frac{2k+1}2)$, where k is an integer. The answer must be expressed in closed form, using factorials.

For k is an integer, when $k\ge0$

$$\Gamma(\frac{2k+1}2)=\frac{2k-1}2\Gamma(\frac{2k-1}2)=\frac{2k-1}2\frac{2k-3}2\Gamma(\frac{2k-3}2)=...=\Gamma(\frac12)\prod_{1}^{k}\frac{2k-1}{2}=\frac{(2k)!}{4^{k}k!}\sqrt{\pi}$$

When $k<0$

$$\Gamma(\frac{2k+1}2)=\frac{\Gamma(\frac{2k+3}2)}{\frac{2k+1}2}=\frac{\Gamma(\frac{2k+5}2)}{\frac{2k+1}2\frac{2k+3}2}=...=\frac{\Gamma(\frac{1}2)}{\prod_{k}^{-1}\frac{2k+1}2}=\sqrt{\pi}{\prod_{1}^{-k}\frac{2}{1-2(-k)}}=\frac{(-4)^{-k}(-k)!}{(-2k)!}\sqrt{\pi}$$

$$\therefore \Gamma(\frac{2k+1}2)=\begin{cases}\mathbf{\frac{(2k)!}{4^{k}k!}\sqrt{\pi}} & when\quad k\ge0\\ \mathbf{\frac{(-4)^{-k}(-k)!}{(-2k)!}\sqrt{\pi}} &  when\quad k<0\end{cases}$$

****

#### 2. A webmaster observes vists to particular website. There are, on the average, 1.5 visits per minute. Find the probability that the webmaster has to wait longer than 8 minutes to observe 10 visits to the site.

Let $T\sim Gamma(\alpha,\beta)$, $T\sim Poisson(\lambda)$. The probability of 10 visits longer than 8 minutes:

$$P(X\le10-1)=1-P(T>8)$$

For T, observed 10 visits and average 1.5 visits per miniute mean $t=8,\ \alpha=10,\ \beta=1.5$. 

$$1-P(T>8)=1-\frac{1}{\Gamma(10)1.5^{10}}8^{10-1}e^{-\frac{8}{1.5}}=\mathbf{0.2423922}$$

For X, no 10 visit in 8 minutes mean $x=9,\ \lambda=\frac{t}\beta=\frac8{\frac23}=12$. 

$$P(X\le10-1)=\frac{12^9}{9!}e^{-12}=\mathbf{0.2423922}$$



```{r, include=FALSE}
ppois(9, 8/(2/3), lower.tail = TRUE, log.p = FALSE)

1-pgamma(8, 10, rate = 1.5, lower.tail = TRUE,log.p = FALSE)

```

Therefore, the probability that 10 visits longer than 8 minutes is 24.24%.

****

#### 3. Find the mode (the value of X for which the density is maximized) of the gamma probability distribution, expressed in terms of the parameters α and β.

For $X\sim Gamma$, $f_X(\alpha,\beta)=\frac{1}{\Gamma(a)\beta^{\alpha}}x^{a-1}e^{-\frac{x}\beta},x>0,\beta>0，\alpha>0$

When X got the maximized value, $f_X(\alpha,\beta)'=\left(\frac{1}{\Gamma(a)\beta^{\alpha}}x^{a-1}e^{-\frac{x}\beta}\right)'=\frac{1}{\Gamma(a)\beta^{\alpha}}\left(x^{a-1}e^{-\frac{x}\beta}\right)'=0$

Because $x>0,\beta>0,\alpha>0$,

$$\implies (x^{a-1}e^{-\frac{x}\beta})'=(a-1)x^{a-2}e^{-\frac{x}\beta}+(-\frac{1}\beta)x^{a-1}e^{-\frac{x}\beta}=e^{-\frac{x}\beta}x^{a-2}(a-1-\frac{x}\beta)=0$$

$$(a-1-\frac{x}\beta)=0\implies \mathbf{x=(α-1)β,\quad α\ge1}$$

****

#### 4. Assume that X has a uniform distribution with parameters α and β. Find $P(\mu−1.5\sigma<X<\mu+1.5\sigma)$  and compare to the amount guaranted by Chebyshev's inequity.

For $X\sim Uniform(a, b),\ b>a,\ μ=\frac{a+b}2,\sigma^2=\frac{(b-a)^2}{12}$, thus

$$P(\mu−1.5\sigma<X<\mu+1.5\sigma)=P(X<(\mu+1.5\sigma)-P(X<(\mu-1.5\sigma)=\frac{\mu+1.5\sigma-a}{b-a}-\frac{\mu-1.5\sigma-a}{b-a}$$

$$=\frac{3\sigma}{b-a}=\frac{3(b-a)}{\sqrt{12}(b-a)}=\frac{\sqrt{3}}{2}=\mathbf{0.8660254}$$

According to Chebyshev's Inequality: for constant k>0, $P(|X−\mu|<\sigma k)\ge1-\frac{1}{k^2}$. Since k=1.5, thus

$$P(\mu−1.5\sigma<X<\mu+1.5\sigma)=P(|X−\mu|<1.5\sigma)\ge1−\frac{1}{1.5^2}=\mathbf{0.5555556}$$

The result shows that  $P(\mu−1.5\sigma<X<\mu+1.5\sigma)$ is larger than the amount guaranteed by Chebyshev's Inequality. Chebyshev's Inequality provides a conservative amount.

```{r, include=FALSE}
sqrt(3)/2
1-1/(1.5^2)
```

****

#### 5. An urn contains 2 black balls and 2 white balls. One ball is selected at random, its color is noted, and them a ball of the opposite color is placed in the urn. The process continues until all balls in the urn are the same color. Let X be the number of draws necessary to achieve this goal. Find the mean and variance of the random variable X.

Let x is the number of draws. When $x=1,3,5,7..$, the probability of achieving this goal is 0. When $x=2,4,6,8..$, the probability of achieving this goal is $\frac14$. let $Y=\frac{X}2$. For $Y\sim Geometric(\frac14)$

$$f_Y(y)=\frac14(1-\frac14)^{y-1}=\frac13(\frac34)^{y}=\frac13(\frac34)^{\frac{x}2}, x=2,4,6,..$$

$$f_X(x)=\begin{cases}\frac13(\frac34)^{\frac{x}2}& x=2,4,6,..\\ 0 & x=1,3,5,.. \end{cases}$$

Because Y is a Geometric function, the mean and variance are

$$E[Y]=\frac{1}p=4=E[\frac{X}2]=\frac{E[X]}2\implies \mathbf{E[X]=8}$$

$$Var[Y]=\frac{1-p}{p^2}=12=Var[\frac{X}2]=\frac{Var[X]}4\implies \mathbf{Var[X]=48}$$

****

#### 6. Only 5 in 1000 adults are afficted with a rare disease for which a diagnostic test has been deveopled. The test is such that when an individual actually has the disease, a positive result will occur 99% of the time, whereas an individual without the disease will show a positive reuslt only 2% of the time. If a randomly selected individual is tested and the result is positive, what is the probability that the individual has the disease?

Accoridng to the Bayes’s Rule,

$$P(Disease|Positive)=\frac{P(Positive|Disease)P(Disease)}{P(Positive|Disease)P(Disease)+P(Positive|Health)P(Health)}$$

$$=\frac{0.005\times 0.99}{0.005\times0.99+0.995\times0.02}=\mathbf{0.1991952}$$

```{r, include=FALSE}
(0.005*0.99)/(0.005*0.99+0.995*0.02)
```

The probability of the individual having disease with positive result is 19.92%.

****

#### 7. If X is arandom variable such that $E[X]=3$ and $E[X^2]=13$, determine a lower bound for the probability P(-2<x<8). (Hint: Use a famous inequity that was mentioned a few problem back.)

For $E(X)=3,\ E(x^2)=13$,

$$Var(X)=E(X^2)−[E(X)]^2=13-9=4$$

According to Chebyshev's Inequality: for constant k > 0, $P\left[|X−E(X)|\ge k\right]\le \frac{Var(X)}{k^2}$

For lower bound by flipping the inequalities:$P\left[|X−E(X)|<k\right]\ge1-\frac{Var(X)}{k^2}$

$$\therefore P(|X-3|<k)=P(3−k<X<k+3)\ge1−\frac4{k^2}$$

When k=5, there is a lower bound P(-2<x<8)

$$P(3−k<X<k+3)=P(−2<X<8)\ge 1− \frac4{25}=\mathbf{0.84}$$

****

#### 8. Consider the following experiment: You simultaneously toss 6 coins. You count the number of "heads" and record whether it is an even or odd number. Then you toss the 6 coins again. The process continues until the second time that you get an even number of "heads". Let X be the number of tosses reuqired to complete the process. Find the distribution of X and give its mean and variance.

Let $a$ is the number of "head" in each toss, each result is $(a,6-a)$. then $S=\{(0,6),(1,5),(2,4),(33),(42),(5,1),(6,0)\}$. The probability of "even head" is $\frac18+\frac18+\frac18+\frac18=\frac12$.

For $X\sim Negative\ Binomial(r=2,p=\frac12)$,

$$f_X(x)=\binom{x-1}{r-1}p^r(1-p)^{x-r}=\binom{x-1}{1}\frac12^2\frac12^{x-2}=(x-1)2^{-x}, x \in 2,3,4..$$

$$\mathbf{E[X]}=\frac{r}p=\mathbf{4};\quad \mathbf{Var[X]}=\frac{r(1-p)}{p^2}=\mathbf{4}$$

****

#### 9. Let X be a random variable with prability function

$$f_X(x)=\begin{cases}cp(1-p)^{x-1} & x=a,a+1,..\\0 & otherwise,\end{cases}$$

where a is a known positive integer. Find c. Then find the mean and variance of X.

For X is a probability function, let F(X) is the CDF of X,

$$F(X)=\sum_{-\infty}^\infty f(x)=\sum_{a}^\infty cp(1-p)^{x-1}=c\left[\sum_{x=1}^\infty p(1-p)^{x-1}-\sum_{x=1}^{a-1}p(1-p)^{x-1}\right]=c\left[\sum_{x=1}^\infty p(1-p)^{x-1}-1+(1-p)^{a-1}\right]$$

For CDF of Geometric function, $\sum_{x=1}^\infty p(1-p)^{x-1}=1, x=1,2,3,..$

And for X is a probability function, $F(X)=1$

$$F(X)=c\left[1-1+(1-p)^{a-1}\right]=c(1-p)^{a-1}=1\implies c=(1-p)^{1-a}$$

$$\therefore f_X(x)=\begin{cases}p(1-p)^{(x+1-a)-1} & x+1-a=1,2,3..\\0 & otherwise\end{cases}$$
Which still is a Geometric function.

$$E(x+1-a)=E(x)+1-a=\frac1p \implies \mathbf{E(x)=\frac1p+a-1}$$

$$Var(x+1-a)=\mathbf{Var(x)=\frac{1-p}{p^2}}$$

****

#### 10. Suppose a random variable X has a probability mass function $p(x)=\frac{\mu^x}{x!}e^{-\mu}, x=0,1,2,..$ Find the values of μ for which x=1 is the unique mode.

This is a Poisson pmf

$$P(X=x)=p_x=\frac{\mu^x}{x!}e^{-\mu}, x=0,1,2.., \mu>0$$

For a discrete, non-negative, integer-valued random variable such that $P(X=x)=p_x, x=1,2,..$ If $X=x$ is the mode, then

$$p_{x-1}\le p_x\implies\frac{p_x}{p_{x-1}}=\frac{\frac{\mu^x}{x!}e^{-\mu}}{\frac{\mu^{x-1}}{(x-1)!}e^{-\mu}}\ge1\implies x\le\mu$$


$$p_{x+1}\le p_x\implies \frac{p_{x+1}}{p_x}=\frac{\frac{\mu^{x+1}}{(x+1)!}e^{-\mu}}{\frac{\mu^x}{x!}e^{-\mu}}\le1\implies x\ge\mu-1$$

If $\mu$ is a positive integer then, by virtue of $\mu-1\le x\le \mu$, the distribution is bimodal with the two modes located at $x=\mu-1$ and $x=\mu$. (D.S.Broca, 2005)

Since $x=1$ is the unique mode, so $x=\lfloor \mu\rfloor$ where $\lfloor\mu\rfloor$ denotes the greatest integer that does not exceed $\mu$. 

Therefore, when $\mathbf{\mu\in(1,2)}$, $x=1$ is the unique mode.


