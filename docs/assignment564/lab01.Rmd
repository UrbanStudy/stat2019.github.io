---
title: 'STAT564 Homework 0'
author: "Shen Qu"
date: "9/25/2017"
output: 
  html_document:
   toc: true
   toc_float: true

---
## Review <!--{.tabset .tabset-fade .tabset-pills}-->
### Problem 1
 Let $X_1,X_2,X_3\sim iid\ N(\mu,\sigma ^2), and\ Z_i=\frac{X_i-\mu}{\sigma}\ for\ i=1,2,3$  
 (a). Specify the probability distribution of $Z_i$ along with the value(s) of parameter(s).  

 > $X_1,X_2,X_3$ are three **independent and identically distributed random variable** that follows a normal distribution with same mean $\mu$ and variance $\sigma^2$  
$Z_i=\frac{X_i-\mu}n$ is called a **standard normal random variable**.  

 $$\therefore Z_{i}\sim iid\ N\left(0,1\right)$$   

 Let $y_{1}=\sum_{i=1}^{3}(\frac{X_{i}-\mu}{\sigma})$  
 (b). Comptute the $E(y_{1})$  
 $$\because X_i\ are\ independent\ variables\ and\ \frac{X_i-\mu}\sigma=Z_i\sim N(0,1)$$
 $$So\quad E(y_1)=E(\sum_{i=1}^3\frac{X_i-\mu}\sigma)=\sum_{i=1}^3E(Z_i)=0$$
 (c). Comptute the $Var(y_{1})$  
 $$And\quad Var(y_{1})=Var(\sum_{i=1}^3\frac{X_i-\mu}\sigma)=\sum_{i=1}^3Var(Z_i)=3$$
 (d). Specify the probability distribution of $y_{1}$ along with the value(s) of parameter(s).  

 > According to the above results, and $Z_i$ is a SND  

 $$\therefore y_1\sim N[E(Z_i),Var(Z_i)]=N(0,3)$$
 (e). Specify the probability distribution of $Z_{i}^2$ along with the value(s) of parameter(s).  

 > According to the definition of **Chi-square** distribution  
   When $Z_i$ is a SND,  $Z_{i}^2$ is a chi square distribution with 1 degree of freedom

 $$\therefore Z_i^2\sim \chi_1^2,\quad E(\chi_1^2)=1,\quad Var(\chi_1^2)=2\times1=1$$

 Let $y_2=\sum_{i=1}^{3}(\frac{X_{i}-\mu}{\sigma})^2$  
 (f). Specify the probability distribution of $y_2$ along with the value(s) of parameter(s). 

 > According to the definition of Chi-square distribution,  when $X_i$ be indepentdent normally distributed random variables with $E(X_i)=\mu,\quad  Var(X_i)=\sigma^2,\quad \frac{X_{i}-\mu}{\sigma}=Z_i$  
then the sum of n squared standard normal random variables follows a $\chi^2$ distribution **with n degrees of freedom**  

 $$\therefore y_2=\sum_{i=1}^3(\frac{X_{i}-\mu}{\sigma})=\sum_{i=1}^3Z_i\sim\chi_3^2,\quad E(\chi_3^2)=3,\quad Var(\chi_3^2)=2\times3=6$$

### Problem 2

 Let $X_{1},X_{2},...X_{n}\sim iid\ N\left(0,\sigma ^{2}\right), and\ \overline{A}=\frac{\sum_{i=1}^{n}X_{i}}{n}$  
 (a). Specify the distribution of $\overline{A}$ along with the value(s) of parameter(s).  

 > According to the definition of sample mean, when $X_i$ are independent identical random variables of size n with **mean of the distribution** $\mu$ and variance $\sigma^2$ from a population, the **sample mean** $\overline{A}=\frac{\sum_{i=1}^{n}X_{i}}{n}$

 $$So\quad E(\overline{A})=E(\frac{\sum_{i=1}^{n}X_{i}}{n})=\frac1n\sum_{i=1}^nE(X_i)=0$$
 $$And\quad Var(\overline{A})=Var(\frac{\sum_{i=1}^{n}X_{i}}{n})=\frac1{n^2}\sum_{i=1}^n[Var(X_i)]=\frac{n\sigma^2}{n^2}=\frac{\sigma^2}n$$
 $$\therefore \overline{A}\sim\ N(0,\frac{\sigma^2}n)$$

 Let $W\sim\chi_{\nu_{1}}^2$ where $\nu_{1}$ is the degrees of freedom, $\overline{X}\ and\ W$ are indipendent.  
 Consider the new random variable $\frac{\overline{X}\sqrt n}{\sigma\sqrt{W/\nu_{1}}}$  
 (b). Specify the distribution of this new randome variable along with the value(s) of parameter(s).  

 > According to the **Central Limit Theorem**, If $X_i\quad i=1,2,...n$ are independent identically distributed random  variables with $E(Y_i)=\mu$ and $Var(Y_i)=\sigma^2<\infty$ and n is sufficiently large, then $\frac{\overline{X}\sqrt n}{\sigma}$ a normal distribution.

 > According to the defination of **t distribution**, when $Z\sim N(0, 1),\ W\sim\chi_{\nu_1}^2$, and Z and W are independent, then

$$\frac{\overline{X}\sqrt n}{\sigma\sqrt{W/\nu_1}}=\frac{Z}{\sqrt{W/\nu_1}}\sim t_{\nu_1}$$  

 > where $t_{\nu_1}$ is the t distribution with $\nu_1$ degrees of freedom.  

$$E(t_{\nu_1})=0\quad when\ \nu_1>1,\quad Var(t_{\nu_1})=\begin{cases}\frac{\nu_1}{\nu_1-2}&when\ \nu_1>2 \\\infty &when\ 1<\nu_1<2\end{cases}$$

 Let $V\sim\chi_{\nu_2}^2$ where $\nu_{2}$ is the degrees of freedom, $V\ and\ W$ are indipendent.  
 Consider the new random variable $\frac{W/\nu_{1}}{V/\nu_{2}}$    
 (c). Specify the distribution of this new randome variable and provide value(s) of parameter(s).  
 
 > According to the definition of **F distribution**, when $W\sim\chi_{\nu_{1}}^2,\quad W\sim\chi_{\nu_{1}}^2,\quad W\ and\ V$ are independent, then the ratio of two independent chi square random variables, each divided by their respective degrees of freedom, follows an F distribution.

$$\frac{W/\nu_{1}}{V/\nu_{2}}\sim F_{\nu_{1},\nu_{2}}$$

 > where $F\nu_1,\nu_2$ is the F distribution with $\nu_1$ and $\nu_2$ degrees of freedom.     

$$E(F_{\nu_{1},\nu_{2}})=\frac{\nu_2}{\nu_2-2}\quad when\ \nu_2>2,\quad Var(F_{\nu_{1},\nu_{2}})=\frac{2\nu_2^2(\nu_1+\nu_2-2)}{\nu_1(\nu_2-2)^2(\nu_2-4)}\quad when\ \nu_2>4$$

### Problem 3

 Let $Y|x=a+bx+\epsilon$ where a, b are constants, $E(\epsilon)=0,\ and\ Var(\epsilon)=\sigma^2$  
 
a. Comptute the $E(Y|x_{0})$  

$$E(Y|x_{0})=E(a+bx_0+\epsilon)=E(a)+E(bx_0)+E(\epsilon)$$
$$\because a,b,x_0\ are\ constant\quad E(a)=a,\ E(bx_0)=bx_0,\ and\quad E(\epsilon)=0$$
$$\therefore E(Y|x_{0})=a+bx_0$$

a. Comptute the $Var(Y|x_{0})$  

$$Var(Y|x_{0})=Var(a+bx_0+\epsilon)=Var(a)+Var(bx_0)+Var(\epsilon)$$

$$\because a,b,x_0\ are\ constant\quad Var(a)=0,\ Var(bx_0)=0,\ and\quad Var(\epsilon)=\sigma^2$$
$$\therefore Var(Y|x_{0})=\sigma^2$$

### Proof $E(\hat{\beta_0})=\beta_0$
We have known: 


 <span>number</span> | <span>meaning</span> | <span>equation</span>
 - | :---------- | :----------
(1) |  population regression model | $y=\beta_1+\beta_0x+\epsilon$
(2) |  assumption_2 of simple linear regression | $E(\epsilon)=0$
(3) |  mean of this distribution | $E(y|x)=a+bx$
(4) |  sample regression model | $y_i=\beta_1+\beta_0x_i+\epsilon_i,\quad i=1,2,3...n$
(5) |  fitted regression model (fitted value)  | $\hat{y_i}=\hat{\beta_1}+\hat{\beta_0}x_i$
(6) | least-squares estimator (slope) | $\hat{\beta_1}=\frac{S_{xy}}{S_{xx}}=\sum_{i=1}^nc_iy_i$
(7) | unbiased estimator (Intercept) |  $\hat{\beta_0}=\overline y-\hat{\beta_1}\overline x=\frac1n{\sum_{i=1}^ny_i}-\overline x(\sum_{i=1}^n c_iy_i)=\sum_{i=1}^n(\frac1n-\overline{x}c_i)y_i$
(8) | sample mean  |  $\overline x=\frac1n\sum_{i=1}^n x_i$
(9) | sum of corrected squares of $x_i$ | $S_{xx}=\sum_{i=1}^nx_i(x_i-\overline x)=\sum_{i=1}^n(x_i-\overline x)^2$ 
(10) | sum of corrected cross-products of $x_i\& y_i$ | $S_{xy}=\sum_{i=1}^nx_i(x_i-\overline x)$ 
(11) | | $c_i=\frac{x_i-\overline x}{S_{xx}}$


 $\text{According to 4, 7}\quad E(\hat{\beta_0})=E[\sum_{i-1}^n(\frac1n-\overline xc_i)(\beta_0+\beta_1x_i+\epsilon_i)]=\frac1n\sum_{i=1}^nE(\beta_0+\beta_1x_i+\epsilon_i)-\overline x\sum_{i=1}^nc_iE(\beta_0+\beta_1x_i+\epsilon_i)]$ 

$\text{According to 2, 3}\quad=\frac1n\sum_{i=1}^n[\beta_0+\beta_1x_i+E(\epsilon_i)]-\overline x\sum_{i=1}^nc_i[\beta_0+\beta_1x_i+E(\epsilon_i)]=\beta_0+\beta_1\frac{\sum_{i=1}^nx_i}n-\beta_0\overline x\sum_{i=1}^nc_i-\beta_1\overline x\sum_{i=1}^nc_ix_i$
 
 $\text{According to 8, 11}\quad \sum_{i=1}^nc_i=\sum_{i=1}^n\frac{x_i-\overline x}{S_{xx}}=\frac1{S_{xx}}\sum_{i=1}^n(x_i-\overline x)=\frac1{S_{xx}}(n\overline x-n\overline x)=0$
 
 $\text{According to 9,11}\quad \sum_{i=1}^nc_ix_i=\frac1{S_{xx}}\sum_{i=1}^nx_i(x_i-\overline x)=\frac{S_{xx}}{S_{xx}}=1$
 
 $$\therefore\quad E(\hat{\beta_0})=\beta_0+\beta_1\overline x-0-\beta_1\overline x=\beta_0$$
