---
title: 'STAT564 Homework 0'
author: "Shen Qu"
date: "9/25/2017"
output: 
  html_document

---
## Review {.tabset .tabset-fade .tabset-pills}
### Problem 1
 Let $X_1,X_2,X_3\sim iid\ N(\mu,\sigma ^2), and\ Z_i=\frac{X_i-\mu}{\sigma}\ for\ i=1,2,3$  
(a). Specify the probability distribution of $Z_i$ along with the value(s) of parameter(s).  

 $X_1,X_2,X_3$ are three _independent and identically distributed_ random variable that follows a normal distribution with same mean $\mu$ and variance $\sigma^2$  
$Z_i=\frac{X_i-\mu}n$ is called a standard normal random variable.  

 $$\therefore Z_{i}\sim iid\ N\left(0,1\right)$$   

 Let $Y_{1}=\sum_{i=1}^{3}(\frac{X_{i}-\mu}{\sigma})$  
(a). Comptute the $E(Y_{1})$  
 $$\because X_i\ are\ independent\ variables\ and\ \frac{X_i-\mu}\sigma=Z_i\sim N(0,1)$$
 $$So\quad E(Y_1)=E(\sum_{i=1}^3\frac{X_i-\mu}\sigma)=\sum_{i=1}^3E(Z_i)=0$$
(a). Comptute the $Var(Y_{1})$  
 $$And\quad Var(Y_{1})=Var(\sum_{i=1}^3\frac{X_i-\mu}\sigma)=\sum_{i=1}^3Var(Z_i)=3$$
(a). Specify the probability distribution of $Y_{1}$ along with the value(s) of parameter(s).  
 > According the above results, and $Z_i$ is a SND  

 $$\therefore Y_1\sim N[E(Z_i),Var(Z_i)]=N(0,3)$$
(a). Specify the probability distribution of $Z_{i}^2$ along with the value(s) of parameter(s).  
 > According the definition of Chi-square distribution  
   When $Z_i$ is a SND,  $Z_{i}^2$ is a chi square distribution with 1 degree of freedom

 $$\therefore Z_i^2\sim \chi_1^2 $$

 Let $Y_2=\sum_{i=1}^{3}(\frac{X_{i}-\mu}{\sigma})^2$  
(a). Specify the probability distribution of $Y_2$ along with the value(s) of parameter(s). 

>According the definition of Chi-square distribution,  when $X_i$ be indepentdent normally distributed random variables with $E(X_i)=\mu$ and $Var(X_i)=\sigma^2$, $\frac{X_{i}-\mu}{\sigma}=Z_i\$  
then the sum of n squared standard normal random variables follows a $\chi^2$ distribution with n degrees of freedom  

 $$\therefore Y_2=\sum_{i=1}^3Z_i\sim\chi_3^2$$
### Problem 2

Let $X_{1},X_{2},...X_{n}\sim iid\ N\left(0,\sigma ^{2}\right), and\ \overline{A}=\frac{\sum_{i=1}^{n}X_{i}}{n}$  
(a). Specify the distribution of $\overline{A}$ along with the value(s) of parameter(s).  
> According the definition, when $X_i$ are independent identical random variables of size n with *mean of the distribution* $\mu$ and *variance* $\sigma^2$ from a population, the *sample mean* $\overline{A}=\frac{\sum_{i=1}^{n}X_{i}}{n}$

2

Center Limit Theorem,

$$E(\overline{A})=0$$
$$Var(\overline{A})=\frac1{n^2}\sum_{i=1}^n[Var(X_i)]=\frac{n\sigma^2}{n^2}=\frac{\sigma^2}n$$
$$\therefore \overline{A}\sim\ N(0,\frac{\sigma^2}n)$$
Let $W\sim\chi_{\nu_{1}}^2$ where $\nu_{1}$ is the degrees of freedom, $\overline{X}\ and\ W$ are indipendent.  
* Consider the new random variable $\frac{\overline{X}\sqrt n}{\sigma\sqrt{W/\nu_{1}}}$  
(a). Specify the distribution of this new randome variable along with the value(s) of parameter(s).  

The **Central Limit Theorem** If Y 1 , Y 2 , . . . , Y n are independent and identically distributed random variables with E ( Y i ) = μ and Var( Y i ) = σ 2 < ∞ , then
Y
n
converges in distribution to a standard normal distnbution as n → ∞ . The key
point is that if n is suffi ciently large, then Y approximately follows a normal
distribution. What constitutes suffi ciently large depends on the underlying
distribution of the Y i ’ s.

If Z ∼ N (0, 1), V ∼ χ ν 2 , and Z and V are independent, then  

$$\frac{\overline{X}\sqrt n}{\sigma\sqrt{W/\nu_{1}}}\sim t_{\nu_{1}}$$  

where t v is the t distribution with v degrees of freedom.  

* Let $V\sim\chi_{\nu_{1}}^2$ where $\nu_{2}$ is the degrees of freedom, $V\ and\ W$ are indipendent.  
* Consider the new random variable $\frac{W/\nu_{1}}{V/\nu_{2}}$    
(a). Specify the distribution of this new randome variable and provide value(s) of parameter(s).  

 - Let V ∼ χν2 , and let W ∼ χ η 2 . If W are independent, then

$$\frac{W/\nu_{1}}{V/\nu_{2}}\sim F_{\nu_{1},\nu_{2}}$$

> where F ν , η is the F distribution with ν and η degrees of freedom. The key point is that the ratio of two independent χ 2 random variables, each divided by their respective degrees of freedom, follows an F distribution.  

### Problem 3
* Let $Y|x=a+bx+\epsilon\ where\ a, b\ are\ constants, E(\epsilon)=0,\ and\ Var(\epsilon)=\sigma^2$  
a. Comptute the $E(Y|x_{0})$  

$$=a+bx$$

a. Comptute the $Var(Y|x_{0})$  

$$=\sigma^2$$

### Proof $E(\hat{\beta_0})=\beta_0$
$$\because \hat{\beta_0}=\overline{y}-\overline{x}\hat{\beta_1}=\frac{\sum_{i=1}^nY_i}{n}-\overline{x}(\sum C_iY_i)=\sum(\frac1n-\overline{x}C_i)$$  
$$So\quad E(\hat{\beta_0})=\sum_{i-1}^n(\frac1n-\overline{x}C_i)E(\beta_0+\beta_1X_i+\epsilon_i)=\sum[\frac1nE(\beta_0+\beta_1X_i+\epsilon_i)-\overline{x}C_iE(\beta_0+\beta_1X_i+\epsilon_i)]$$ 
$$=\frac1n\sum(\beta_0+\beta_1X_i+\epsilon_i)-$$
 $E(\hat{\beta_0})=\beta_0$
 Because X is independent variable
 
#### If
 
 
##### $\therefore $
