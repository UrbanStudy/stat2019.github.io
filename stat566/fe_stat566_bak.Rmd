---
title: ""
author: ""
date: ''
output:
  pdf_document: 
geometry: margin=0.5in
fontfamily: mathpazo
fontsize: 12pt
spacing: double
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache=FALSE, results="markup", tidy=T)
```

```{r eval=FALSE, include=FALSE}
install.packages("ggplot2")
install.packages("ggpubr")
install.packages("mosaic")
install.packages("agricolae")
install.packages("DescTools")
install.packages("emmeans")
install.packages("kableExtra")
```

```{r eval=FALSE, include=FALSE}
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(agricolae)
library(DescTools)
library(dplyr)
library(car)
library(olsrr)
library(pander)
library(emmeans)
library(knitr)
library(kableExtra)
```

### Question 1

  \textcolor[rgb]{0.7,0.7,0.7}{A process engineer is testing the yield of a product manufactured on randomly selected three machines. Each machine can be operated at a large number of power settings and only two power settings are randomly selected for this study. Furthermore, a machine has only three stations on which the product is formed. An experiment is conducted in which each machine is tested at both power settings, and three observations on yield are taken from each station. The runs are made in random order.
Part of the ANOVA table computed for the above experiment incorrectly treating all main effects as fixed and all combinations of factors as crossed is given below.}

 -----------------------------------
 Source                   	SS
 -------------------------- -------- 
 Machine                  	21.436   
 
 Power                    	845.698
 
 Station                  	16.980
 
 Machine × Power          	0.383
 
 Machine × Station        	16.603
 
 Power × Station          	16.303
 
 Machine × Power × Station	12.905
 
 Error                    	61.760
 
 Total	                    992.068
 -----------------------------------

The model of the nested & crossed Design is

$$y_{ijkl}=\mu+\tau_i+\beta_{j}+\gamma_{k(i)}+(\tau\beta)_{ij}+(\beta\gamma)_{jk(i)}+\varepsilon_{l(ijk)}$$

for $i=1,2,3$ is the number of Machine being compared; 
$j=1,2$ is the number of Power being compared; 
$k=1,2,3$ is the number of stations; 
$l=1,2,3$ is the number of replication; 

$\mu$ is the overall true mean response;

$\tau_i$ is the random effect of $i^{th}$ level of Machine;

$\beta_{j}$ is the random effect of $j^{th}$ level of Power;

$\gamma_{k(i)}$ is the main fixed effect of $k^{th}$ stations nested in $i^{th}$ level of Machine;

$(\tau\beta)_{ij}$ is the interaction effect of $i^{th}$ level of Machine and $j^{th}$ level of Power;

$(\beta\gamma)_{jk(i)}$ is the interaction effect of $j^{th}$ level of Power and $k^{th}$ stations nested in $i^{th}$ level of Machine.

$y_{ijkl}$ is response value for the $l^{th}$ replication for $k^{th}$ stations nested in $i^{th}$ level of Machine when $j^{th}$ level of Power is applied;

$\varepsilon_{l(ijk)}$ is random error for the $l^{th}$ replication for $k^{th}$ stations nested in $i^{th}$ level of Machine when $j^{th}$ level of Power is applied.

Assumptions: 

|$\varepsilon_{l(ijk)}\sim iid N(0,\sigma^2)$|$\tau_{i}\sim iid N(0,\sigma_{\tau}^2)$|$\beta_{j}\sim iid N(0,\sigma_{\beta}^2)$|
|--- |--- |--- |
$\sum_{k=1}^3\gamma_{k(i)}=0$|$(\tau\beta)_{ij}\sim iid N(0,\sigma_{\tau\beta}^2)$|$(\beta\gamma)_{jk(i)}\sim iid N(0,\frac{3-1}{3}\sigma_{\beta\gamma}^2)$
$\varepsilon_{l(ijk)}$, $\tau_{i}$, $\beta_{j}$, $(\tau\beta)_{ij}$, and $(\beta\gamma)_{jk(i)}$ are independent. For restricted model, $\sum_{k=1}^3(\beta\gamma)_{jk(i)}=0$
 
\textcolor[rgb]{0.7,0.7,0.7}{Produce the corrected ANOVA table with Source, df, SS, MS, EMS, F value along with numerator and denominator df, and p value for each test.}

|source|i(r)|j(r)|k(f)|l(r)| df  |  SS |  EMS   | F   |
| --   | -  | -  | -  | -  |---- | ----- | -------| --- |
|A     |1|b|c|n|a-1|$SS_A$|$\sigma^2+cn\sigma^2_{\tau\beta}+bcn\sigma^2_{\tau_{i}}$|$\frac{MS_{A}}{MS_{AB}}$|
|$\tau_{i}$| |2|3|3|3-1|21.436|$\sigma^2+9\sigma^2_{\tau\beta}+18\sigma^2_{\tau_{i}}$|$df_{2,2}$|
|(r)| | | | | | | ||
|B     |a|1|c|n|b-1|$SS_B$|$\sigma^2+cn\sigma^2_{\beta\gamma}+acn\sigma^2_{\tau\beta}$|$\frac{MS_{B}}{MS_{AB}}$|
|$\beta_{j}$|3| |3|3|2-1|845.698|$\sigma^2+9\sigma^2_{\beta\gamma}+27\sigma^2_{\tau\beta}$|$df_{1,2}$|
|(r)| | | | |   | | ||
|C(A)  |1|b|0|n|a(c-1)|$SS_C+SS_{AC}$|$\sigma^2+n\sigma^2_{\beta\gamma}+\frac{bn\sum\limits_{k=1}^c\gamma_{k(i)}^2}{c-1}$|$\frac{MS_{C(A)}}{MS_{BC(A)}}$|
|$\gamma_{k(i)}$| |2| |3|3(3-1)|16.980+16.603|$\sigma^2+3\sigma^2_{\beta\gamma}+3\sum\limits_{k=1}^3\gamma_{k(i)}^2$|$df_{6,6}$|
|(f) | | | | | | | ||
|AB    |1|1|c|n|(a-1)(b-1)|$SS_{AB}$|$\sigma^2+cn\sigma^2_{\tau\beta}$|$\frac{MS_{AB}}{MS_{E}}$|
|$(\tau\beta)_{ij}$| | |3|3|(3-1)(2-1)|0.383|$\sigma^2+9\sigma^2_{\tau\beta}$|$df_{2,36}$|
|(r)| | | | | | | ||
|BC(A) |1|1|0|n|a(b-1)(c-1)|$SS_{BC}+SS_{ABC}$|$\sigma^2+n\sigma^2_{\beta\gamma}$|$\frac{MS_{BC(A)}}{MS_{E}}$|
|$(\beta\gamma)_{jk(i)}$| | | |3|3(2-1)(3-1)|16.303+12.905|$\sigma^2+3\sigma^2_{\beta\gamma}$|$df_{6,36}$|
|(r)| | | | | | | ||
|Error |1|1|1|1|abc(n-1)|$SS_{E}$|$\sigma^2$||
|(r)| | | | |3×2×3(3-1)|61.760| ||
|Total | | | | |abcn-1|$SS_{T}$|
|      | | | | |3×2×3×3-1|992.068|

\textcolor[rgb]{0.7,0.7,0.7}{Compute the p value assuming you don’t have access to a computer. If an exact F test is not available, construct a Satterthwaite (approximate) F statistic and its df values. Provide the numerical values for df, SS, MS, F in the table.}
The numerical values:

|source|df|  SS  |  MS   | F   | p |
|  -  | -| ----  |  ---  | ---- | - |
|A    |2 |21.436 |21.436/2=10.718|$\frac{10.718}{0.1915}=55.96867$|0.01755351
|B    |1 |845.698|845.698 |$\frac{845.698}{0.1915}=4416.178$|0.0002263633
|C(A) |6 |33.583 |33.583/6=5.597167|$\frac{5.597167}{4.868}=1.149788$|0.4348901
|AB   |2 |0.383  |0.383/2=0.1915|$\frac{0.1915}{1.715556}=0.1116256$|0.8946874
|BC(A)|6 |29.208 |29.208/6=4.868|$\frac{4.868}{1.715556}=2.837564$|0.02292305
|Error|36|61.760 |61.760/36=1.715556||
|Total|53|992.068|

```{r eval=FALSE, include=FALSE}
pf(55.96867, 2, 2,log = FALSE, lower.tail = F)
pf(4416.178, 1, 2,log = FALSE, lower.tail = F)
pf(1.149788, 6, 6,log = FALSE, lower.tail = F)
pf(0.1116256, 2, 36,log = FALSE, lower.tail = F)
pf(2.837564, 6, 36,log = FALSE, lower.tail = F)
```

### Question 2

\textcolor[rgb]{0.7,0.7,0.7}{Consider the linear model for a two-stage nested design with B nested in A as given below. Using only the given information here,}

$y_{ijk}=\mu+\tau_i+\beta_{j(i)}+\varepsilon_{(ij)k}$; for $i=1,…,a$; $j=1,…,b$; $k=1,…,n$;

Assumptions:
$\varepsilon_{(ij)k}\sim iid N(0,\sigma^2)$; 
$\tau_i\sim iid N(0,\sigma_{\tau}^2)$;
$\sum_{j=1}^b\beta_j(i)=0$;
$\varepsilon_{(ij)k}$, $\tau_{i}$ are independent.

$\bar y_{i..}=\frac1{bn}\sum_{j=1}^b\sum_{k=1}^ny_{ijk}$;
$\bar y_{.j.}=\frac1{an}\sum_{i=1}^a\sum_{k=1}^ny_{ijk}$;
$\bar y_{ij.}=\frac1n\sum_{k=1}^ny_{ijk}$;
$\bar y_{...}=\frac{1}{abn}\sum_{i=1}^a\sum_{j=1}^b\sum_{k=1}^ny_{ijk}$

(a). \textcolor[rgb]{0.7,0.7,0.7}{Derive the least squares estimator of $\beta_{j(i)}$. Provide the appropriate constraints about estimators used when solving normal equations. (Use only sum to zero constraints)}

This is a two-stage nested design with fixed factor B nested in random factor A. 
$\varepsilon_{(ij)k}=y_{ijk}-\mu-\tau_i-\beta_{j(i)}$

$$SSE=\sum_i^a\sum_j^b\sum_k^n(y_{ijk}-\mu-\tau_i-\beta_{j(i)})^2$$

Derive
For $i=1,…,a$, $j=1,…,b$,

$\frac{\partial SSE}{\partial \tau_i}=2\sum_j^b\sum_k^n(y_{ijk}-\hat\mu-\hat\tau_i-\hat\beta_{j(i)})(-1)=0$

For $\sum_j^b\hat\beta_{j(i)}=0$, $\bar y_{i..}=\frac1{bn}\sum_{j=1}^b\sum_{k=1}^ny_{ijk}$,

$\sum_j^b\sum_k^ny_{ijk}=bn\hat\mu+bn\hat\tau_i+n\sum_j^b\hat\beta_{j(i)}=bn\bar y_{i..}\implies \hat\mu+\hat\tau_i=\bar y_{i..}$

$\frac{\partial SSE}{\partial \beta_{j(i)}}=2\sum_k^n(y_{ijk}-\hat\mu-\hat\tau_i-\hat\beta_{j(i)})(-1)=0$

For $\bar y_{ij.}=\frac1n\sum_{k=1}^ny_{ijk}$,

$\sum_k^ny_{ijk}=n\hat\mu+n\hat\tau_i+n\hat\beta_{j(i)}=n\bar y_{ij.}\implies \hat\mu+\hat\tau_i+\hat\beta_{j(i)}=\bar y_{ij.}$

$$\implies \hat\beta_{j(i)}=\bar y_{ij.}-\bar y_{i..}$$

 ---

(b).  \textcolor[rgb]{0.7,0.7,0.7}{Derive $E(MS_{B(A)})$ for this model.}

For $\sum_j^b\hat\beta_{j(i)}=0$,

$\bar y_{i..}=\frac1{bn}\sum_{j=1}^b\sum_{k=1}^ny_{ijk}=\mu+\tau_{i}+\frac1b \sum_{j=1}^b\beta_{j(i)}+\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}=\mu+\tau_{i}+\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}$

$\bar y_{ij.}=\frac1{n}\sum_{k=1}^ny_{ijk}=\mu+\tau_{i}+\beta_j+\frac1{n}\sum_{k=1}^n\varepsilon_{ijk}$

$$\bar y_{ij.}-\bar y_{i..}=\beta_{j(i)}+\frac1{n}\sum_{k=1}^n\varepsilon_{ijk}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}$$

For B has fixed effect, $E[\beta_{j(i)}]=\beta_{j(i)}$, $V[\beta_{j(i)}]=0$,
$Cov[\beta_{j(i)},\frac1{n}\sum_{k=1}^n\varepsilon_{(ij)k}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}]=0$

For $\varepsilon_{(ij)k}\sim iid N(0,\sigma^2)$, $E[\varepsilon_{(ij)k}]=0$, $V[\varepsilon_{(ij)k}]=\sigma^2$

$E[\bar y_{ij.}-\bar y_{i..}]=E[\beta_{j(i)}+\frac1{n}\sum_{k=1}^n\varepsilon_{(ij)k}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{(ij)k}]=\beta_{j(i)}$

$Var[\bar y_{ij.}-\bar y_{i..}]=Var[\beta_{j(i)}+\frac1{n}\sum_{k=1}^n\varepsilon_{(ij)k}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{(ij)k}]$

$=Var[\beta_{j(i)}]+Var[\frac1{n}\sum_{k=1}^n\varepsilon_{ijk}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}]+2Cov[\beta_{j(i)},\frac1{n}\sum_{k=1}^n\varepsilon_{ijk}-\frac1{bn}\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}]$

$=0+\frac1{n^2}\sum_{k=1}^nVar[\varepsilon_{ijk}]+\frac{1}{b^2n^2}\sum_{j=1}^b\sum_{k=1}^nVar[\varepsilon_{ijk}]-\frac{2}{bn^2}Cov[\sum_{k=1}^n\varepsilon_{ijk},\sum_{j=1}^b\sum_{k=1}^n\varepsilon_{ijk}]+0$

$$=\frac1n\sigma^2+\frac{\sigma^2}{bn}-\frac{2\sigma^2}{bn}=\frac{(b-1)\sigma^2}{bn}$$

For $MS_{B(A)}=SS_{B(A)}/df_{B(A)}=\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^b\hat\beta_{j(i)}^2=\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^b(\bar y_{ij.}-\bar y_{i..})^2$

$$E(MS_{B(A)})=\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^bE[(\bar y_{ij.}-\bar y_{i..})^2]=\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^b\left\{Var[\bar y_{ij.}-\bar y_{i..}]+E[\bar y_{ij.}-\bar y_{i..}]^2\right\}$$

$$=\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^b\left\{\beta_{j(i)}^2+\frac{(b-1)\sigma^2}{bn}\right\}=\sigma^2+\frac{n}{a(b-1)}\sum_{i=1}^a\sum_{j=1}^b\beta_{j(i)}^2$$


### Question 3 

  \textcolor[rgb]{0.7,0.7,0.7}{Two laboratories were used to determine the purity of a chemical compound synthesized from 3 sources. Within each of these laboratories, 3 technicians were used to carry out the analysis.
}

  \textcolor[rgb]{0.7,0.7,0.7}{Analyze the data. If you have to decide between unrestricted and restricted models, then make a decision and provide reasons.}
  
```{r echo=FALSE, fig.show='hold', message=FALSE, out.width='33%'}
fe_table_chem <- readxl::read_xlsx("Chemical.xlsx")
fe_table_chem$Lab <- as.factor(fe_table_chem$Lab)
fe_table_chem$Technician <- as.factor(fe_table_chem$Technician)
fe_table_chem$Source <- as.factor(fe_table_chem$Source)
str(fe_table_chem)

ggpubr::ggline(fe_table_chem,"Source", "Purity", add = c("mean", "jitter"), shape= "Lab", color = "Lab", linetype = "Lab", ylab= "Purity", xlab="Source")
ggpubr::ggline(fe_table_chem,"Source", "Purity", add = c("mean", "jitter"), shape= "Technician", color = "Technician", linetype = "Technician", ylab= "Purity", xlab="Source")
library(ggplot2)
ggplot(fe_table_chem, aes(x=Technician,y=Purity, shape = Source, color=Source))+ stat_summary() + labs(y= "Mean Purity", x="Technician", shape="Source", color = "Source")+facet_wrap(facet="Lab")+theme_light()
```

```{r include=FALSE}
library(kableExtra)
library(mosaic)
library(emmeans)
```

The above plots show that: The average purity analysed in Lab 1 is lower than that from Lab 2.
There is not much difference in the average purity among technicians.
The average purity of a chemical compound synthesized from source 2 and 3 are higher than that from source 1.
There is not much difference in the average purity between sources 2 and 3.

```{r echo=FALSE}
kable(favstats(Purity ~ Lab, data=fe_table_chem),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(Purity ~ Technician, data=fe_table_chem),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(Purity ~ Source, data=fe_table_chem),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
```

There is not much difference in the average purity of sources 3 between lab 1 and 2.

Not all the lines are parallel in the interaction plot. Therefore, in the model, there is the interaction effect of source level and technicians nested in the lab. The Tables show the same thing with the numerical summaries for each factor level and their combinations.

```{r echo=FALSE}

kable(favstats(Purity ~ Lab+Source, data=fe_table_chem),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(Purity ~ Technician+Source, data=fe_table_chem),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
```

This is a neseted and crossed design. Three fixed sources apply on all random selected technicians nested in fixed labs.

$$y_{ijkl}=\mu+\tau_i+\beta_{j(i)}+\gamma_{k}+(\tau\gamma)_{ik}+(\beta\gamma)_{j(i)k}+\varepsilon_{(ijk)l}$$

for $i=1,2$; $j=1,2,3$; $k=1,2,3$; $l=1,2,3$; 

$\mu$ is the overall true mean response;

$\tau_i$ is the fixed main effect of $i^{th}$ level of labs;

$\beta_{j(i)}$ is the random effect of $j^{th}$ level of technicians nested in $i^{th}$ level of labs;

$\gamma_{k}$ is the main fixed effect of $k^{th}$ level of sources;

$(\tau\gamma)_{ik}$ is the interaction effect of $i^{th}$ level of labs and $k^{th}$ level of sources;

$(\beta\gamma)_{j(i)k}$ is the interaction random effect of $k^{th}$ level of sources and $j^{th}$ level of technicians nested in $i^{th}$ level of labs.

$y_{ijkl}$ is response value for the $l^{th}$ replication for $j^{th}$ level of technicians nested in $i^{th}$ level of labs when $k^{th}$ level of sources is applied;

$\varepsilon_{(ijk)l}$ is random error for the $l^{th}$ replication for $j^{th}$ level of technicians nested in $i^{th}$ level of labs when $k^{th}$ level of sources is applied.

Assumptions: Usually, the technicians in a lab are skillful. From the above plots, the technicians' performances are stable. The covariance between two observations from the same level of the random factor can be either positive or negative. Thus we assume this is an **restricted model**. $\varepsilon_{(ijk)l}$, $\beta_{j(i)}$, and $(\beta\gamma)_{j(i)k}$ are independent.



|$\varepsilon_{(ijk)l}\sim iid N(0,\sigma^2)$|$\sum_{i=1}^2\tau_{i}=0$|$\sum_{k=1}^3\gamma_{k}=0$|$\beta_{j(i)}\sim iid N(0,\sigma_{\beta}^2)$|
| --- | --- | --- | ----- |
|$\sum_{i=1}^2(\tau\gamma)_{ik}=0$|$\sum_{k=1}^3(\tau\gamma)_{ik}=0$|$\sum_{i=1}^2(\beta\gamma)_{j(i)k}=0$|$(\beta\gamma)_{j(i)k}\sim iid N(0,\frac{2-1}{2}\sigma_{\beta\gamma}^2)$|

```{r echo=F, message=FALSE}
library("GAD")
fe_table_chem$Lab_f <- as.fixed(fe_table_chem$Lab)
fe_table_chem$Technician_r <- as.random(fe_table_chem$Technician)
fe_table_chem$Source_f <- as.fixed(fe_table_chem$Source)
fe_model_chem1 <- aov(formula = Purity ~ Lab_f*Source_f+Technician_r%in%Lab_f+Source_f*Technician_r%in%Lab_f, data=fe_table_chem)
pander::pander(gad(fe_model_chem1))
library(lme4)
fe_model_chem2 <- lmer(formula = Purity ~ Lab*Source+(1|Lab:Technician)+(1|Source:Lab:Technician), data=fe_table_chem, REML = TRUE)
```

The ANOVA table shows that only sources have significant effects on the average purity of a chemical compound synthesized at 0.05 significance level (p-value=0.0001783).

 --------------------------------------------------------------------------------
 Groups           Name               Variance Std.Dev.
 ----------------------- ----------- -------- -------- --------------------------
 Source:Lab:Technician   (Intercept)  0.00    0.000    $\sigma^2_{\beta\gamma}=0$
 
 Lab:Technician          (Intercept)  0.00    0.000    $\sigma^2_{\beta}=0$
 
 Residual                            17.87    4.227    $\sigma^2=17.87$
 --------------------------------------------------------------------------------
 
 ------------------------------------------------------------------------------
      &nbsp;        2.5 %    97.5 % 
 ------------------ -------- ------- ------------------------------------------
     **.sig01**        0      1.539   $CI_{\sigma^2_{\beta\gamma}}:(0,1.539^2)$

   **.sig02**          0      1.603   $CI_{\sigma^2_{\beta}}:(0,1.603^2)$

   **.sigma**        3.337    4.873   $CI_{\sigma^2}:(3.337^2,4.873^2)$
 ------------------------------------------------------------------------------

The results of variance components and condidence intervals show that none of the effects related with technician has significant variance on average value of purity at 0.05 significance level. The variance of interaction effect between sources and technicians nested in labs is zero with confidence intervals ($0,1.539^2$) at 0.05 significance level. The variance of technicians nested in labs is zero with confidence intervals ($0,1.603^2$) at 0.05 significance level. 

**Conclusion:**  As the main effects of sources shown in the above tables, the average purity is different with sources. The average purity from source 1 is lowest (12.72222). The the average purity from source 2 and 3 are 21.38889 and 20.27778 respectively. The selections of labs and technicians don't change this result.

```{r eval=F, include=FALSE, message=FALSE}
summary(fe_model_chem2)
pander::pander(confint(fe_model_chem2))
```
 
```{r eval=FALSE, include=FALSE}
fe_chem_effect <- coef(fe_model_chem1)[2:18]
library(daewr)
halfnorm(fe_chem_effect,names(fe_chem_effect),alpha=0.05)
library(gghalfnorm)
gghalfnorm(x = fe_chem_effect,labs =names(fe_chem_effect), nlab = 6)+ theme_light()
```

```{r eval=FALSE, include=FALSE}
fe_model_chem3 <- lmer(formula = Purity ~ Lab+Source+Source:Lab+Source:(1|Lab:Technician), data=fe_table_chem, REML = TRUE)
fe_model_chem4 <- aov(Purity ~ Lab*Source, data=fe_table_chem)

fe_model_chem5 <- aov(formula = Purity ~ Lab_f+Source_f+Source_f:Lab_f, data=fe_table_chem)
gad(fe_model_chem5)

summary(fe_model_chem4)
pander::pander(anova(fe_model_chem4))
pander::pander(confint(fe_model_chem5))
```


```{r echo=FALSE, out.width='25%',fig.show='hold'}
fe_residual_chem <- rstudent(fe_model_chem2)
plot(fe_residual_chem)
plot(fe_model_chem2)
# fechem_y_hat <- fitted(fe_model_chem2)
# plot(fechem_y_hat,fe_residual_chem)
qqnorm(fe_residual_chem)
qqline(fe_residual_chem)
hist(fe_residual_chem)
```

In the plots of residuals versus predicted value of purity, there is no significant pattern on this plot besides that more values occur when the predicted value is higher. Therefore, the fitted model is good enough to describe the relationship between the mean value of purity and the labs, technician, and sources.

The residuals in this plot are almost symmetrically distributed about zero and hence zero mean assumption is not violated. Further, the vertical deviation of the residuals from zero is about same for each predicted value and hence the constant variance assumption is not violated.

The points are along the straight line in the normal qq plot shown at bottom left and the histogram of residuals shown at the top right is about normal. These plots show no violation of normal distribution assumption of residuals.

  \textcolor[rgb]{0.7,0.7,0.7}{Report your code and/or output at the end of the analysis.}

```{r eval=F}
favstats(Purity ~ Source, data=fe_table_chem)
favstats(Purity ~ Lab, data=fe_table_chem)
favstats(Purity ~ Lab+Source, data=fe_table_chem)
favstats(Purity ~ Technician, data=fe_table_chem)
favstats(Purity ~ Technician+Source, data=fe_table_chem)
fe_table_chem$Lab_f <- as.fixed(fe_table_chem$Lab)
fe_table_chem$Technician_r <- as.random(fe_table_chem$Technician)
fe_table_chem$Source_f <- as.fixed(fe_table_chem$Source)
fe_model_chem1 <- aov(formula = Purity ~ Lab_f*Source_f+Technician_r%in%Lab_f+Source_f*Technician_r%in%Lab_f, data=fe_table_chem)
gad(fe_model_chem1)

fe_model_chem2 <- lmer(formula = Purity ~ Lab*Source+(1|Lab:Technician)+(1|Source:Lab:Technician), data=fe_table_chem, REML = TRUE)
summary(fe_model_chem2)
confint(fe_model_chem2)

fe_residual_chem <- rstudent(fe_model_chem2)
plot(fe_residual_chem)
plot(fe_model_chem2)
qqnorm(fe_residual_chem)
qqline(fe_residual_chem)
hist(fe_residual_chem)
```

  
### Question 4

  \textcolor[rgb]{0.7,0.7,0.7}{A baker wanted to determine the effect that the amount of fat in a recipe of cookie dough would have on the texture of the cookie. The baker also wanted to determine whether the temperature (°F) at which the cookies were baked would have an influence on the texture of the surface. The texture of the cookie is measured by determining the amount of force (g) required to penetrate the cookie surface.}
  \textcolor[rgb]{0.7,0.7,0.7}{On a given day, the baker made a batch of cookie dough for each of the 4 recipes and baked one cookie from each batch in the oven at one time. The baker continued this process each of 4 days so that a single cookie is baked at 3 different temperatures in one day.The data are given in Cookie Excel file.}
  \textcolor[rgb]{0.7,0.7,0.7}{Analyze the data and answer the baker's questions. If you have to decide between unrestricted and restricted models, then make a decision and provide reasons.}
  
```{r, echo=FALSE, out.width='30%',fig.show='hold'}
fe_table_cookie <- readxl::read_xlsx("Cookie.xlsx")
fe_table_cookie$day <- as.factor(fe_table_cookie$day)
fe_table_cookie$temp <- as.factor(fe_table_cookie$temp)
fe_table_cookie$fat <- as.factor(fe_table_cookie$fat)
str(fe_table_cookie)

ggpubr::ggline(fe_table_cookie,"day", "force", add = c("mean", "jitter"), shape= "temp", color = "temp", linetype = "temp", ylab= "force", xlab="day")
ggpubr::ggline(fe_table_cookie,"day", "force", add = c("mean", "jitter"), shape= "fat", color = "fat", linetype = "fat", ylab= "force", xlab="day")
ggpubr::ggline(fe_table_cookie,"temp", "force", add = c("mean", "jitter"), shape= "fat", color = "fat", linetype = "fat", ylab= "force", xlab="temp")

# library(ggplot2)
# ggplot(fe_table_cookie, aes(x=fat,y=force, shape=day, color=day))+ stat_summary() + labs(y= "Mean force", x="fat", shape="day", color = "day")+facet_wrap(facet="temp")+theme_light()
```

```{r include=FALSE}
library(kableExtra)
library(mosaic)
library(emmeans)
```

The above plots show that:
There is not much difference in the average force of the cookie from different days or form different fat.
The tables show the same thing with the numerical summaries for each factor level and their combinations.
The average force of the cookie are higher when the temperature is higher.

```{r echo=FALSE, collapse=T}
kable(favstats(force ~ day, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(force ~ fat, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(force ~ temp, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
```

Not all the lines are parallel in the interaction plot. Therefore, in the model, there is the interaction effect of day and temperature. 

```{r echo=FALSE}
kable(favstats(force ~ day+fat, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(force ~ temp+fat, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
kable(favstats(force ~ temp+day, data=fe_table_cookie),format="latex",booktabs=T) %>%kable_styling("striped", full_width = F,font_size = 8)%>%column_spec(7,background ="#EAFAF1")
```

This is a simple Split-Plot design model (fat is whole-plot factor and temperature is split-plot factor)

$$y_{ijk}=\mu+\tau_i+\beta_{j}+(\tau\beta)_{ij}+\gamma_{k}+(\tau\gamma)_{ik}+(\beta\gamma)_{jk}+(\tau\beta\gamma)_{ijk}+\varepsilon_{ijk}$$

for $i=1,2,3,4$; $j=1,2,3$; $k=1,2,3,4$ 

$\mu$ is the overall true mean response;

$\tau_i$ is the effect of $i^{th}$ replication of days;

$\beta_{j}$ is the main effect of $j^{th}$ level of temperature (effect of split-plot factor);

$(\tau\beta)_{ij}$ is the interaction effect of $i^{th}$ replication and $j^{th}$ level of temperature;

$\gamma_{k}$ is the main effect of $k^{th}$ level of fat (effect of whole-plot factor);

$(\tau\gamma)_{ik}$ is the interaction effect of $i^{th}$ replicatin and $k^{th}$ level of fat(whole-plot error);

$(\beta\gamma)_{jk}$ is the interaction effect of $j^{th}$ level of temperature and $k^{th}$ level of fat;

$(\tau\beta\gamma)_{ijk}$ is the interaction effect of $i^{th}$ replicatin, $j^{th}$ level of temperature and $k^{th}$ level of fat (sub-plot error);

$y_{ijk}$ is response value for the $i^{th}$ replication when $j^{th}$ level of temperature and $k^{th}$ level of fat are applied;

$\varepsilon_{ijk}$ is random error for the $i^{th}$ replication when $j^{th}$ level of temperature and $k^{th}$ level of fat are applied.

Assumptions: For an experienced baker, he/she will try to let the recipe and temperature are accurate in each day. the covariance between two observations from the same level of the random factor can be either positive or negative. Thus, we assume this is a **restricted model**.

|$\varepsilon_{ijk}\sim iid N(0,\sigma^2)$|$\tau_i\sim iid N(0,\sigma_{\tau}^2)$|
| --- | --- | ------ |
|$\sum_{j=1}^3\beta_{j}=0$|$\sum_{j=1}^3(\tau\beta)_{ij}=0$|$(\tau\beta)_{ij}\sim iid N(0,\frac{3-1}{3}\sigma_{\tau\beta}^2)$|
|$\sum_{k=1}^4\gamma_{k}=0$|$\sum_{k=1}^4(\tau\gamma)_{ik}=0$|$(\tau\gamma)_{ik}\sim iid N(0,\frac{4-1}{4}\sigma_{\tau\gamma}^2)$|
|$\sum_{j=1}^3(\beta\gamma)_{jk}=0$|$\sum_{k=1}^4(\beta\gamma)_{jk}=0$|
|$\sum_{j=1}^3(\tau\beta\gamma)_{ijk}=0$|$\sum_{k=1}^4(\tau\beta\gamma)_{ijk}=0$|$(\tau\beta\gamma)_{ijk}\sim iid N(0,\frac{(3-1)(4-1)}{3\times4}\sigma_{\tau\beta\gamma}^2)$

$\varepsilon_{ijk}$, $\tau_{i}$, $(\tau\beta)_{ij}$, $(\tau\gamma)_{ik}$, $(\beta\gamma)_{jk}$, and $(\tau\beta\gamma)_{ijk}$ are independent.

Since this is a simple replicated factorial design, I use $(\tau\beta\gamma)_{ijk}$ to compute SSE and df.

```{r echo=F}
library("GAD")
fe_table_cookie$day_r <- as.random(fe_table_cookie$day)
fe_table_cookie$temp_f <- as.fixed(fe_table_cookie$temp)
fe_table_cookie$fat_f <- as.fixed(fe_table_cookie$fat)
fe_model_cookie1 <- aov(formula = force ~ day_r+fat_f+fat_f%in%day_r+temp_f%in%day_r+temp_f+temp_f:fat_f, data=fe_table_cookie)
pander::pander(gad(fe_model_cookie1))

library(lme4)
fe_model_cookie2 <- lmer(formula = force ~ (1|day)+fat+(1|day:fat)+temp+(1|day:temp)+temp:fat, data=fe_table_cookie, REML = TRUE)
```

The results show the interaction effect of day and fat is not significant at 0.05 significance level (P-value=0.5082). 

The interaction effect of day and temperature is significant at 0.05 significance level (P-value=$6.251\times{10}^{-08}$).

The interaction effect of temperature and fat is not significant at 0.05 significance level (P-value=0.05113).

```{r eval=FALSE, include=FALSE}
summary(fe_model_cookie2)
pander::pander(confint(fe_model_cookie2))
```

 ----------------------------------------------------------------------------
 Groups   Name        Variance  Std.Dev. 
 -------- ----------- --------- --------- -----------------------------------
 day:fat  (Intercept) 1.697e-15 4.120e-08 $\hat\sigma^2_{\tau\gamma}=0$
 
 day:temp (Intercept) 6.252e-01 7.907e-01 $\hat\sigma^2_{\tau\beta}=0.6252$
 
 day      (Intercept) 4.055e-01 6.368e-01 $\hat\sigma^2_{\tau}=0.4055$
 
 Residual             9.856e-02 3.140e-01 $\hat\sigma^2=0.9856$
 ----------------------------------------------------------------------------
  
 -------------------------------------------------------------------------------------
      &nbsp;         2.5 %    97.5 %  
 ------------------ --------- -------- -----------------------------------------------
    **.sig01**         0      0.1906    $CI_{\sigma^2_{\tau\gamma}}:(0,0.1906^2)$

   **.sig02**       0.4371     1.242    $CI_{\sigma^2_{\tau\beta}}:(0.4371^2,1.242^2)$

   **.sig03**         0       1.626     $CI_{\sigma^2_{\tau}}:(0,1.626^2)$

   **.sigma**       0.2116    0.3492    $CI_{\sigma^2}:(0.2116^2,0.3492^2)$
 -------------------------------------------------------------------------------------

The results of variance components show the variance of interaction term of days and fat is negligible and hence dropping interaction term of days and fat.

```{r echo=F}
fe_model_cookie3 <- aov(formula = force ~ day_r+fat_f+temp_f+temp_f%in%day_r+temp_f:fat_f, data=fe_table_cookie)
pander::pander(gad(fe_model_cookie3))

fe_model_cookie4 <- lmer(formula = force ~ (1|day)+fat+temp+(1|day:temp)+temp*fat, data=fe_table_cookie, REML = TRUE)
```

The ANOVA table of new model shows that there is a significant interaction effect from the day and temperature, on average amount of force (g) (p-value=$4.298\times10^{-10}$).
Similarly, there is a significant interaction effect from the fat and temperature, on average amount of force (g) (p-value=0.03544).

This means that the effects of day v.s.temperature and fat v.s.temperature on the force are not independent. Hence, the simple effects must be tested.
The variances and confidence intervals don't change.

```{r eval=FALSE, include=FALSE}
summary(fe_model_cookie4)
# pander::pander(anova(fe_model_cookie))
pander::pander(confint(fe_model_cookie4))
```

 ----------------------------------------------------------------------------
 Groups   Name        Variance  Std.Dev. 
 -------- ----------- --------- --------- -----------------------------------
 day:temp (Intercept)  0.62520   0.7907    $\hat\sigma^2_{\tau\beta}=0.6252$
 
 day      (Intercept)  0.40554   0.6368    $\hat\sigma^2_{\tau}=0.40554$
 
 Residual              0.09856   0.3140    $\hat\sigma^2=0.9856$
 ----------------------------------------------------------------------------

 -------------------------------------------------------------------------------------
      &nbsp;         2.5 %    97.5 %  
 ------------------ --------- -------- -----------------------------------------------
   **.sig02**       0.4371     1.242    $CI_{\sigma^2_{\tau\beta}}:(0.4371^2,1.242^2)$

   **.sig03**         0       1.626     $CI_{\sigma^2_{\tau}}:(0,1.626^2)$

   **.sigma**       0.2116    0.3492    $CI_{\sigma^2}:(0.2116^2,0.3492^2)$
 -------------------------------------------------------------------------------------

Since there are several simple effects comparison tests, the Tukey’s adjustment was used to compute p value to reduce the experimentwise error rate. The Tables below show the summary of all those simple effect comparison tests.

For all levels of fat, the mean forces are significantly different between 350°F and 400°F (p value=0.0011369, 0.0005290, 0.0004966, 0.0004663 respectively).

When the fat was 4, 6 and 8, the mean forces are significantly different between 375°F and 400°F (p value=0.0145686, 0.0127251,0.0432588 respectively).

When the fat was 8, the mean forces are significantly different between 350°F and 375°F (p value=0.0231342).

When temperature was 350°F, the mean forces are significantly different between the fat of 2 and 8 (p value=0.0063518).

When temperature was 375°F, the mean forces are significantly different between the fat of 2 and 6 (p value=0.0326101).

For all the rest of temperature, the mean forces are not significantly different between any value of fat.

When the day 1, the mean forces are not significantly different between 375°F and 400°F (p value=0.3674143).

For all the rest of days, the mean forces are significantly different between any value of temperature.

For all levels of temperature, the mean forces are significantly different between the day 2 v.s. day 3, and day 2 v.s. day 4 (p value<0.0002).

When temperature was 350°F and 400°F, the mean forces are significantly different between the day 1 and day 2  (p value=0.0421959, 0.0000001).

When temperature was 375°F, the mean forces are significantly different between the day 1 v.s. day 3, and day 1 v.s. day 4 (p value=0.0000000).

```{r echo=FALSE, out.width='30%',fig.show='hold'}
temp_fat <- pairs(lsmeans(fe_model_cookie4,~ temp|fat))
fat_temp <- pairs(lsmeans(fe_model_cookie4,~ fat|temp))
kable(test(rbind(temp_fat,fat_temp),adjust="tukey"),format="latex")%>%kable_styling("condensed",full_width=F,font_size = 8)%>%row_spec(c(2,5,6,8:12,15,20),bold =T)%>%row_spec(c(2,5,6,8:12,15,20),background ="#EAFAF1")
temp_day <- pairs(lsmeans(fe_model_cookie3,~ temp_f|day_r))
day_temp <- pairs(lsmeans(fe_model_cookie3,~ day_r|temp_f))
kable(test(rbind(temp_day,day_temp),adjust="tukey"),format="latex")%>%kable_styling("condensed",full_width=F,font_size = 8)%>%row_spec(c(1,2,4:13,16,17,20:23,25,28,29),bold =T)%>%row_spec(c(1,2,4:13,16,17,20:23,25,28,29),background ="#EAFAF1")
```

**Conclusion:** Choosing a higher temperature for a given amount of fat can get a harder texture of the surface. In most of the cases, changing fat for a given temperature doesn't change the texture.

For a given temperature, almost all of the amount of fat cannot change the texture but different days don't give consistent results. If the baker wants to examine the texture for a specific temperature, he/she should check what other factors in different days may affect the results and redo the experiment.

```{r echo=FALSE, out.width='25%',fig.show='hold'}
fe_residual_cookie <- rstudent(fe_model_cookie4)
plot(fe_residual_cookie)
plot(fe_model_cookie4)
# fe_chem_y_hat <- fitted(fe_model_cookie4)
# plot(fe_chem_y_hat,fe_residual_cookie)
qqnorm(fe_residual_cookie)
qqline(fe_residual_cookie)
hist(fe_residual_cookie)
```

In the plots of residuals versus predicted value of purity, there is no significant pattern on this plot. Therefore, the fitted model is good enough to describe the relationship between the mean value of focre and the days, temperature, and fats.

The residuals in this plot are almost symmetrically distributed about zero and hence zero mean assumption is not violated. Further, the vertical deviation of the residuals from zero is about same for each predicted value and hence the constant variance assumption is not violated.

The points are along the straight line in the normal qq plot shown at bottom left and the histogram of residuals shown at the top right is about normal. These plots show no violation of normal distribution assumption of residuals.

```{r eval=F}
favstats(force ~ day, data=fe_table_cookie)
favstats(force ~ fat, data=fe_table_cookie)
favstats(force ~ temp, data=fe_table_cookie)
favstats(force ~ day+fat, data=fe_table_cookie)
favstats(force ~ temp+fat, data=fe_table_cookie)
favstats(force ~ temp+day, data=fe_table_cookie)

fe_table_cookie$day_r <- as.random(fe_table_cookie$day)
fe_table_cookie$temp_f <- as.fixed(fe_table_cookie$temp)
fe_table_cookie$fat_f <- as.fixed(fe_table_cookie$fat)
fe_model_cookie1 <- aov(formula = force ~ day_r+fat_f+fat_f%in%day_r+temp_f%in%day_r+temp_f+temp_f:fat_f, data=fe_table_cookie)
gad(fe_model_cookie1)

fe_model_cookie2 <- lmer(formula = force ~ (1|day)+fat+(1|day:fat)+temp+(1|day:temp)+temp:fat, data=fe_table_cookie, REML = TRUE)
summary(fe_model_cookie2)
confint(fe_model_cookie2)

fe_model_cookie3 <- aov(formula = force ~ day_r+fat_f+temp_f+temp_f%in%day_r+temp_f:fat_f, data=fe_table_cookie)
gad(fe_model_cookie3)
fe_model_cookie4 <- lmer(formula = force ~ (1|day)+fat+temp+(1|day:temp)+temp*fat, data=fe_table_cookie, REML = TRUE)
summary(fe_model_cookie4)
confint(fe_model_cookie4)

temp_fat <- pairs(lsmeans(fe_model_cookie4,~ temp|fat))
fat_temp <- pairs(lsmeans(fe_model_cookie4,~ fat|temp))
test(rbind(temp_fat,fat_temp),adjust="tukey")
temp_day <- pairs(lsmeans(fe_model_cookie3,~ temp_f|day_r))
day_temp <- pairs(lsmeans(fe_model_cookie3,~ day_r|temp_f))
test(rbind(temp_day,day_temp),adjust="tukey")

fe_residual_cookie <- rstudent(fe_model_cookie4)
plot(fe_residual_cookie)
plot(fe_model_cookie4)
qqnorm(fe_residual_cookie)
qqline(fe_residual_cookie)
hist(fe_residual_cookie)
```

