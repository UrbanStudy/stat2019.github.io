---
title: "STAT561 Fall 2018 HW6"
author: 'Shen Qu'
date: "11/8/2018"
output: html_document
---

**3.15** There is an interesting relationship between negative binomial and gamma random variables, which may sometimes provide a useful approximation. Let Y be a negative binomial random variable with parameters r and p, where p is the success probability.
Show that as $p\rightarrow0$, the mgf of the random variable pY converges to that of a gamma distribution with parameters r and 1.





****
**3.24** Many "named" distributions are special cases of the more common distributions already discussed. For each of the following named distributions derive the form of the pdf, verify that it is a pdf, and calculate the mean and variance.

(a) If $X\sim$ exponential($\beta$), then $Y = X^{1/\gamma}$ has the Weibull($\gamma,\beta$) distribution, where $\gamma>0$ is a constant.


****
(b) If $X\sim$ exponential($\beta$), then $Y =(2X/\beta)^{1/2}$ has the _Rayleigh_ _distribution_.

****
(c) If $X\sim$ gamma(a, b), then $Y=1/X$ has the inverted gamma IG(a, b) distribution. (This distribution is useful in Bayesian estimation of variances; see Exercise 7.23.)

****
(d) If $X\sim$ gamma(3/2, b)), then $Y =(X/\beta)^{1/2}$ has the Maxwell distribution.

****
(e) If $X\sim$ exponential(1), then $Y =\alpha-\gamma \log X$ has the Gumbel($\alpha,\gamma$) distribution, where $-\infty<\alpha<\infty$ and $\gamma>0$. (The Gumbel distribution is also known as the extreme value distribution.)



****
**3.39** Consider the Cauchy family defined in Section 3.3. This family can be extended to a location-scale family yielding pdfs of the form.

$$f(x|\mu,\sigma)=\frac{1}{\sigma\pi\left(1+(\frac{x-\mu}{\sigma})^2\right)},\ -\infty<x<\infty$$

The mean and variance do not exist for the Cauchy distribution. So the parameters $\mu$ and $\sigma^2$ are not the mean and variance. But they do have important meaning. Show that if X is a random variable with a Cauchy distribution with parameters $\mu$ and $\sigma^2$, then:

(a) $\mu$ is the median of the distribution of X, that is, $P(X\ge\mu)=P(X\le\mu)=1/2$.

****
(b) $\mu+\sigma$ and $\mu-\sigma$ are the quartiles of the distribution of X, that is, $P(X\ge\mu+\sigma)=P(X\le\mu-\sigma)=1/4$. (Hint: Prove this first for $\mu=0$ and $\sigma=1$ and then use Exercise 3.38.)


3.28 Show that each of the following families is an exponential family.

(a) normal family with either parameter $\mu$ or $\sigma$ known

****
(b) gamma family with either parameter $\alpha$ or $\beta$ known or both unknown

****
(c) beta family with either parameter $\alpha$ or $\beta$ known or both unknown

****
(d) Poisson family

****
(e) negative binomial family with r known, 0<p<1

**3.33** For each of the following families:

(i) Verify that it is an exponential family.

(ii) Describe the curve on which the 9 parameter vector lies.

(iii) Sketch a graph of the curved parameter space.

(a) $n(\theta, \theta)$

****
(b) $n(\theta, a\theta)$, a known

****
(c) gamma($\alpha, 1/\alpha$)

****
(d) $f(x|\theta) = C exp (-(x-\theta)^4)$ , C a normalizing constant

**3.38** Let Z be a random variable with pdf f(z). Define $z_{\alpha}$ to be a number that satisfies this relationship:
$$\alpha= P ( Z > z_{\alpha}) =\int_{z_{\alpha}}^{\infty}f(z)dz.$$
Show that if X is a random variable with pdf ($l/\sigma)f((x-\mu)/\sigma$) and $x_{\alpha}=\sigma z_{\alpha}+\mu$, then $P(X>x_{\alpha})=\alpha$. (Thus if a table of $z_{\alpha}$ values were available, then values of $x_{\alpha}$ could be easily computed for any member of the location-scale family.)