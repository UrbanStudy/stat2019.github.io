---
title: 'STAT564 Homework 2'
author: "Shen Qu"
date: "10/31/2018"
output: 
  html_document:
    toc: false
    toc_float: false
---

```{r setup, include=F}
knitr::opts_chunk$set(message=FALSE, warning=F, echo=TRUE)
options(width = 2000)
options(repos="https://cran.rstudio.com")
```

### Problem 1
The weight and systolic blood pressure of 26 randomly selected a group of adults are given in Weight vs BP text file

 <!--https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals-->

```{r, echo=TRUE}
# Load the package 
library(readxl)
library(tidyverse)
library(broom)
# Import Data
table_weight_bp <- read_table2("Weight vs BP.txt")
# Observe the data frame
head(table_weight_bp)
# visualizng Satisfaction and Age
table_weight_bp %>% ggplot(aes(Weight,SystolicBP))+geom_point()+geom_smooth(method="lm", level=0.95)
# build the model
model_wei_bp <- lm(SystolicBP ~ Weight, data=table_weight_bp)
model_wei_bp%>% summary()
confint(model_wei_bp, level = 0.99)
anova(model_wei_bp)
model_wei_bp_origin <- lm(SystolicBP ~ Weight+0, data=table_weight_bp)
model_wei_bp_origin
```
(a) Fit a simple linear regression model to predict blood pressure using weight. Provide only the fitted equation with correct variable names here.

* The simple linear model is $\hat{systolic blood pressure}=69.1044+0.4194Weight$

(b) Test for significance of true intercept of this model at 5% significance and provide the conclusion along with p-value.

*The p-value is $1.71\times e^{-05}$, which is much smaller than 0.05. We can know the true intercept is 69.10437 on 95% confidence level.

(c) Report a 99% confidence interval for true intercept of this model.

*The 99% confidence interval for true intercept of this model is (32.9955223 105.2132233).

(d) Fit a simple linear regression model through origin to predict blood pressure using weight. Provide only the fitted equation with correct variable names here.

* The model through origin is $\hat{systolic blood pressure}=0.7916Weight$

(e) Compare quality of two models and recommend only one model. Provide valid reasons for your recommendation.

We should choose the model with intercept. The model through origin implies the assumption of zero blood presure for zero weight. Either the blood presure or weight has a reasonable range. We also should not extrapolation the trend. 


### Problem 2: 
Show your work to get full points.
Consider the simple linear regression model:
$$y_i=β_0+β_1 x_i+ε_i\quad    for  i=1,2,…,n$$

which can be written for each observation as
$$
\begin{matrix}
  y_1=\beta_0+\beta_1x_1+\varepsilon_1 \\
  y_2=\beta_0+\beta_1x_2+\varepsilon_2 \\
  \vdots\quad\quad  \vdots\quad\quad   \vdots\quad\quad  \vdots  \\
  y_n=\beta_0+\beta_1x_n+\varepsilon_n 
 \end{matrix}
$$
 (a) Write this model in matrix form. Provide all the vectors and design matrix along with dimensions. Use the above format so that you can write only 4 rows for each vector and matrix. For example, Y vector is written as
$$
\mathbf{Y}=\begin{bmatrix} y_1 \\ y_2 \\ \vdots  \\ y_n \end{bmatrix}_{n\times1} 
\mathbf{X}=\begin{bmatrix} 1 & x_{1} \\ 1 & x_{2} \\ \vdots & \vdots  \\ 1 & x_{n} \end{bmatrix}_{n\times2} 
\mathbf{β}=\begin{bmatrix} \beta_0 \\ \beta_1 \end{bmatrix}_{n\times2}+
\mathbf{ε}=\begin{bmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots  \\ \varepsilon_n \end{bmatrix}_{n\times1}
$$
 (b) Compute $\mathbf{X'X}$ (show all the main steps)

$$
\mathbf{X'X}=\begin{bmatrix} 1 &  1 &\cdots &1 \\   x_{1} & x_{2} & \cdots & x_{n} \end{bmatrix}_{2\times{n}} 
\begin{bmatrix} 1 & x_{1} \\ 1 & x_{2} \\ \vdots & \vdots  \\ 1 & x_{n} \end{bmatrix}_{n\times2}=
\begin{bmatrix} n & x_{1}+x_{2}+\cdots+x_{n} \\ x_{1}+x_{2}+\cdots+x_{n} & x_1^2+x_2^2+\cdots+x_n^2  \end{bmatrix}_{2\times2}
$$

 (c) Compute $\mathbf{(X'X)^{-1}}$ (show all the main steps)
Hint: The inverse of a nonsingular is obtained by 1) replacing every element of the matrix with its cofactor, 2) transposing the resulting matrix, 3) dividing by the determinant of the origin matrix.

$$
\mathbf{|X'X|}^{-1}=\frac1{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\begin{bmatrix} x_1^2+x_2^2+\cdots+x_n^2  & -(x_{1}+x_{2}+\cdots+x_{n}) \\ -(x_{1}+x_{2}+\cdots+x_{n}) & n \end{bmatrix}_{2\times2}=\frac1{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\begin{bmatrix} \sum_{i=1}^nx_i^2 & -(\sum_{i=1}^nx_i) \\ -(\sum_{i=1}^nx_i) & n \end{bmatrix}_{2\times2}
$$

(d) Compute X'Y (show all the main steps)

$$
\mathbf{X'Y}=\begin{bmatrix} 1 &  1 &\cdots &1 \\   x_{1} & x_{2} & \cdots & x_{n} \end{bmatrix}_{2\times{n}} 
\begin{bmatrix} y_1 \\ y_2 \\ \vdots  \\ y_n \end{bmatrix}_{n\times1}=\begin{bmatrix} y_1 + y_2 +\cdots + y_n \\ x_{1}y_1 + x_{2}y_2 + \cdots + x_{n}y_n \end{bmatrix}_{2\times{1}}=\begin{bmatrix} \sum_{i=1}^ny_i \\ \sum_{i=1}^nx_{i}y_i \end{bmatrix}_{2\times{1}}
$$

(e) Compute (X'X)^(-1) X'Y (show all the main steps).
The final answer is the expression for the least squares estimator of β
$$
\mathbf{\hatβ}=\mathbf{(X'X)^{-1} X'Y}=\frac1{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\begin{bmatrix} \sum_{i=1}^nx_i^2 & -\sum_{i=1}^nx_i \\ -\sum_{i=1}^nx_i & n \end{bmatrix}_{2\times2}\begin{bmatrix} \sum_{i=1}^ny_i \\ \sum_{i=1}^nx_{i}y_i \end{bmatrix}_{2\times{1}} \\


=\frac1{n\sum_{i=1}^nx_i^2-(\sum_{i=1}^nx_i)^2}\begin{bmatrix} \sum_{i=1}^nx_i^2\sum_{i=1}^ny_i & -\sum_{i=1}^nx_i\sum_{i=1}^nx_{i}y_i \\ -\sum_{i=1}^nx_i\sum_{i=1}^ny_i & n\sum_{i=1}^nx_{i}y_i \end{bmatrix}_{2\times2}
$$
in the multiple linear regression model when k=1. It reduces to the same expression you learned for the slope and intercept for simple linear regression model.

(f) Also, we know that if $Var(ε_i )=σ^2\ and\ Cov(ε_i,ε_j )=0 for i≠j$, 
$$Var(\mathbf{\hatβ})=σ^2(\mathbf{X'X})^{-1}$$
From this result, show that 
(i)  $Var(\hatβ_0)= σ^2 [1/n+ x^2/S_{xx}]$  

$$Var(\mathbf{\hatβ_0})=σ^2(\mathbf{X'X})^{-1}=\frac{\sigma^2}{1\sum_{i=1}^1x_i^2-(\sum_{i=1}^1x_i)^2}\begin{bmatrix} \sum_{i=1}^nx_i^2 & -(\sum_{i=1}^nx_i) \\ -(\sum_{i=1}^nx_i) & n \end{bmatrix}_{2\times2}$$

(ii)  $Var(\hatβ_1)=σ^2/S_{xx}$

$$Var(\mathbf{\hatβ_1})=σ^2(\mathbf{X'X})^{-1}=\frac{\sigma^2}{2\sum_{i=1}^2x_i^2-(\sum_{i=1}^2x_i)^2}\begin{bmatrix} \sum_{i=1}^nx_i^2 & -(\sum_{i=1}^nx_i) \\ -(\sum_{i=1}^nx_i) & n \end{bmatrix}_{2\times2}$$

(iii)  $Cov(β_0,β_1)=-(\bar x σ^2)/S_{xx}$

$$Cov(\mathbf{\hatβ_0,\hatβ_1})=σ^2(\mathbf{X'X})^{-1}$$