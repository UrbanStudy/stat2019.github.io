---
title: 'STAT564 Homework 1'
author: "Shen Qu"
date: "10/15/2018"
output: 
  html_document:
    toc: false
    toc_float: false
---

```{r setup, include=F}
knitr::opts_chunk$set(message=FALSE, warning=F, echo=TRUE)
options(width = 2000)
options(repos="https://cran.rstudio.com")
```

## Problem 1: 

Exercise 2.3 (Page 58): Table B.2 presents data collected during a solar energy project at Georgia Tech.
y: Total heat flux (kwatts)
x1 : Insolation (watts/m2) 
x2 : Position of focal point in east direction (inches) 
x3 : Position of focal point in south direction (inches) 
x4 : Position of focal point in north direction (inches) 
x5 : Time of day


```{r, echo=TRUE}
# Load the package 
library(readxl)
library(tidyverse)
library(broom)
# Import Data
table_b2 <- read_xlsx("Table B.2.xlsx")

# Observe the data frame
head(table_b2)

# visualizng y and x4
table_b2 %>% ggplot(aes(x4,y))+geom_point()+geom_smooth(method="lm", level=0.99)
```

a. Fit a simple linear regression model relating total heat flux y (kilowatts) to the radial deflection of the deflected rays $x_4$ (milliradians).

```{r}
# build the model
model_y_x4 <- lm(y ~ x4, data=table_b2)
model_y_x4
```

The model is $y=607.1-21.4x_4$

b. Construct the analysis-of-variance table and test for significance of regression.

```{r}
model_y_x4 %>% summary()
```

c. Find a 99% CI on the slope.

```{r}
model_y_x4 %>% augment()
```

d. Calculate $R^2$.

e. Find a 95% CI on the mean heat flux when the radial deflection is 16.5 milliradians.

```{r}
predict(model_y_x4, newdata = data.frame(x4=16.5), level=0.95)
```

## Problem 2: 

Exercise 2.4 (Page 58): Table B.3 presents data on the gasoline mileage performance of 32 different automobiles.
y : Miles/gallon 
x1 : Displacement (cubic in.) 
x2 : Horsepower (ft-lb) 
x3 : Torqne (ft-lb) 
x4 : Compression ratio 
x5 : Rear axle ratio Source : Motor Trend , 1975
x6 : Carburetor (barrels)
x7 : No. of transmission speeds 
x8 : Overall length (in.) 
x9 : Width (in.) 
x10 : Weight (lb) 
x11 : Type of transmission (A automatic; M manual)

```{r, echo=TRUE}

# Import Data
table_b3 <- read_xlsx("Table B.3.xlsx")

# Observe the data frame
glimpse(table_b3)

# visualizng y and x1
table_b3 %>% ggplot(aes(x1,y))+geom_point()+geom_smooth(method="lm")
```

a. Fit a simple linear regression model relating gasoline mileage y (miles per gallon) to engine displacement x l (cubic inches).

b. Construct the analysis-of-variance table and test for significance of regression.

c. What percent of the total variability in gasoline mileage is accounted for by the linear relationship with engine displacement?

d. Find a 95% CI on the mean gasoline mileage if the engine displacement is 275 in.3

e. Suppose that we wish to predict the gasoline mileage obtained from a car with a 275-in.3 engine. Give a point estimate of mileage. Find a 95% prediction interval on the mileage.

f. Compare the two intervals obtained in parts d and e. Explain the difference between them. Which one is wider, and why?


## Problem 3: 

Exercise 2.12 (Page 60): The number of pounds of steam used per month at a plant is thought to be related to the average monthly ambient temperature. The past year’s usages and temperatures follow.

```{r, echo=TRUE}

# Import Data
table_12 <- read_xlsx("Problem 2.12.xlsx")

# Observe the data frame
glimpse(table_12)

# visualizng y and x1
table_12 %>% ggplot(aes(Temperature,`Usage/l000`,col=as.factor(Month)))+geom_point( )+geom_smooth(method="lm")
```

a. Fit a simple linear regression model to the data.

b. Test for significance of regression.

c. Plant management believes that an increase in average ambient temperature of 1 degree will increase average monthly steam consumption by 10,000lb. Do the data support this statement?

d. Construct a 99% prediction interval on steam usage in a month with average ambient temperature of 58°.

## Problem 4: 

Exercise 2.25 (Page 65): Consider the simple linear regression model $y=\beta_0+\beta_1x + \epsilon$, with $E(\epsilon)=0,\ Var(\epsilon)=\sigma^2$, and $\epsilon$ uncorrelated.

a. Show that $Cov(\hat\beta_0, \hatβ_1)=−\overline x\sigma^2 S_{xx}$.

b. Show that $Cov(\overline y,\beta_1) = 0$.

## Problem 5: 
Exercise 2.26 (Page 65): Consider the simple linear regression model $y=\beta_0+\beta_1x + \epsilon$, with $E(\epsilon)=0,\ Var(\epsilon)=\sigma^2$, and $\epsilon$ uncorrelated.

a. Show that $E(MS_R)=\sigma^2+\beta_1^2S_{xx}$

b. Show that $E(MS_{Res})=\sigma^2$.

## Problem 6: 

Exercise 2.27 (Page 65): Suppose that we have fit the straight-line regression model $\hat y=\hat\beta_0+\hat\beta_1x$ but the response is affected by a second variable x 2 such that the true regression function is

$$E(y)=\beta_0+\beta_1x_1+\beta_2x_2$$

a. Is the least-squares estimator of the slope in the original simple linear regression model unbiased?

b. Show the bias in $\hat\beta_1$

## Problem 7: 
Exercise 2.32 (Page 66): Consider the simple linear regression model $y=\beta_0+\beta_1x + \epsilon$ where the intercept $\beta_0$ is known.

a. Find the least-squares estimator of $\beta_1$ for this model. Does this answer seem reasonable?

b. What is the variance of the slope ($\hat\beta_1$) for the least-squares estimator found in part a?

c. Find a 100(1−α) percent CI for $\beta_1$. Is this interval narrower than the
estimator for the case where both slope and intercept are unknown?
