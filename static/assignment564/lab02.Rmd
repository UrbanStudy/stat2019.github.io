---
title: 'STAT564 Homework 1'
author: "Shen Qu"
date: "10/15/2018"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=F}
knitr::opts_chunk$set(message=FALSE, warning=F, echo=TRUE)
options(width = 2000)
options(repos="https://cran.rstudio.com")
```

## Problem 1: 

Exercise 2.3 (Page 58): Table B.2 presents data collected during a solar energy project at Georgia Tech.
y: Total heat flux (kwatts)
x1 : Insolation (watts/m2) 
x2 : Position of focal point in east direction (inches) 
x3 : Position of focal point in south direction (inches) 
x4 : Position of focal point in north direction (inches) 
x5 : Time of day


```{r, echo=TRUE}
# Load the package 
library(readxl)
library(tidyverse)
library(broom)
# Import Data
table_b2 <- read_xlsx("Table B.2.xlsx")

# visualizng y and x4
table_b2 %>% ggplot(aes(x4,y))+geom_point()+geom_smooth(method="lm", level=0.99)
```

a. Fit a simple linear regression model relating total heat flux y (kilowatts) to the radial deflection of the deflected rays $x_4$ (milliradians).

```{r}
# build the model
model_y_x4 <- lm(y ~ x4, data=table_b2)
model_y_x4
```

The model is $y=607.1-21.4x_4$

b. Construct the analysis-of-variance table and test for significance of regression.

```{r}
model_y_x4 %>% summary()

model_y_x4 %>% augment()
```

c. Find a 99% CI on the slope.

```{r}
model_y_x4 %>% augment()
```

d. Calculate $R^2$.

e. Find a 95% CI on the mean heat flux when the radial deflection is 16.5 milliradians.

```{r}
predict(model_y_x4, newdata = data.frame(x4=16.5))
```

## Problem 2: 

Exercise 2.4 (Page 58): Table B.3 presents data on the gasoline mileage performance of 32 different automobiles.
y : Miles/gallon 
x1 : Displacement (cubic in.) 
x2 : Horsepower (ft-lb) 
x3 : Torqne (ft-lb) 
x4 : Compression ratio 
x5 : Rear axle ratio Source : Motor Trend , 1975
x6 : Carburetor (barrels)
x7 : No. of transmission speeds 
x8 : Overall length (in.) 
x9 : Width (in.) 
x10 : Weight (lb) 
x11 : Type of transmission (A automatic; M manual)

a. Fit a simple linear regression model relating gasoline mileage y (miles per gallon) to engine displacement x l (cubic inches).

b. Construct the analysis-of-variance table and test for significance of regression.

c. What percent of the total variability in gasoline mileage is accounted for by the linear relationship with engine displacement?

d. Find a 95% CI on the mean gasoline mileage if the engine displacement is 275 in.3

e. Suppose that we wish to predict the gasoline mileage obtained from a car with a 275-in.3 engine. Give a point estimate of mileage. Find a 95% prediction interval on the mileage.

f. Compare the two intervals obtained in parts d and e. Explain the difference between them. Which one is wider, and why?


## Problem 3: 

Exercise 2.12 (Page 60): The number of pounds of steam used per month at a plant is thought to be
related to the average monthly ambient temperature. The past year’s usages and temperatures follow.

a. Fit a simple linear regression model to the data.

b. Test for signifi cance of regression.

c. Plant management believes that an increase in average ambient temperature of 1 degree will increase average monthly steam consumption by 10,000 lb. Do the data support this statement?

d. Construct a 99% prediction interval on steam usage in a month with average ambient temperature of 58 ° .

## Problem 4: Exercise 2.25 (Page 65)

Consider the simple linear regression model y = β 0 + β 1 x + ε , with E ( ε ) = 0,
Var( ε ) = σ 2 , and ε uncorrelated.
a. Show that C ov βˆ0, βˆ1 σ
( ) = −x 2 Sxx .
b. Show that C ov(y, β1 ) = 0.

## Problem 5: Exercise 2.26 (Page 65)

Consider the simple linear regression model y = β 0 + β 1 x + ε , with E ( ε ) = 0,
Var( ε ) = σ 2 , and ε uncorrelated.
a. Show that E(MSR ) =σ 2 +β Sxx
1
2 .
b. Show that E ( MS Res ) = σ 2 .

## Problem 6: Exercise 2.27 (Page 65)

Suppose that we have fi t the straight - line regression model yˆ = βˆ0 +βˆ1x1 but
the response is affected by a second variable x 2 such that the true regression
function is E(y) = β0 +β1x1 +β2x2

a. Is the least - squares estimator of the slope in the original simple linear regression model unbiased?

b. Show the bias in ˆβ1

## Problem 7: Exercise 2.32 (Page 66)

Consider the simple linear regression model
y = β0 +β1x +ε
where the intercept β0 is known.
a. Find the least-squares estimator of β1 for this model. Does this answer
seem reasonable?

b. What is the variance of the slope (ˆβ1) for the least-squares estimator found
in part a?

c. Find a 100(1−α) percent CI for β1. Is this interval narrower than the
estimator for the case where both slope and intercept are unknown?


### Visualization

1. Visualize a single variable
```{r, echo=TRUE}
ggplot(my_df, aes(x=mpg)) + geom_histogram()
```

```{r, echo=TRUE}
ggplot(my_df, aes(x=wt)) + geom_histogram()
```

2. Visualize a pair of numeric variables
```{r, echo=TRUE}
ggplot(my_df, aes(x=wt, y=mpg)) + geom_point()
```

## Correlation

```{r, echo=TRUE}
cor(my_df$mpg, my_df$wt)
```

## Regression
In R, run linear regressions with `lm` (short for **l**inear **m**odel):

```{r, echo=TRUE}
lm(mpg ~ wt, data=my_df)
```

## More detailed regression results

1. Pass the results from `lm()` to `summary()` for more detailed information:
```{r, echo=TRUE}
lm(mpg ~ wt, data=my_df) %>%
  summary
```

For better formatting of the results (pretty print), we can use the `texreg` package:
```{r, echo=TRUE}
## Install and load texreg package
install.packages("texreg")
library(texreg)

# Pretty print regression results on screen
lm(mpg ~ wt, data=my_df) %>%
  screenreg

# Save regression results to a html file
lm(mpg ~ wt, data=my_df) %>%
  htmlreg(file="output/lm_mpg-wt.html")
```

## Visualize regression results

```{r, echo=TRUE}
ggplot(my_df, aes(x=wt, y=mpg)) + geom_point() + geom_smooth(method = "lm", se = FALSE)
```

## Diagnostic plots of regression

We will use the `ggfortify` package to generate the diagnostic plots for regression
```{r, echo=TRUE}
## Install and load ggfortify package
install.packages("ggfortify")
library(ggfortify)

lm(mpg ~ wt, data=my_df) %>%
  autoplot()

# Since we need the regression results in many places, 
# it would be easier to save it into a R variable
mpg_lm <- lm(mpg ~ wt, data=my_df)

# Save the diagnostic plots as a png file
ggsave("output/mpg_lm_diag.png")

```

